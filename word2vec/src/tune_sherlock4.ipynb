{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Word Vectors with TensorFlow: Optimizer Selection\n",
    "### Adam Optimizer\n",
    "*Patrick Coady (pcoady@alum.mit.edu)*\n",
    "\n",
    "This notebook explores (with Momentum optimizer):\n",
    "1. Learning rates\n",
    "\n",
    "I found the Adam optimizer to run very slow - perhaps 5x slower per epoch. I cut off this experiment at 20 epochs after seeing learning performance was also no better. I haven't heard of Adam being inherently slow, but I am not going to investigate further at this time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordvector import WordVector\n",
    "from windowmodel import WindowModel\n",
    "import docload\n",
    "from plot_util import plot_results\n",
    "\n",
    "import numpy as np\n",
    "import sklearn.utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = ['../data/adventures_of_sherlock_holmes.txt',\n",
    "        '../data/hound_of_the_baskervilles.txt',\n",
    "        '../data/sign_of_the_four.txt']\n",
    "word_array, dictionary, num_lines, num_words = docload.build_word_array(\n",
    "    files, vocab_size=50000, gutenberg=True)\n",
    "print('Document loaded and processed: {} lines, {} words.'\n",
    "      .format(num_lines, num_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = WindowModel.build_training_set(word_array)\n",
    "\n",
    "# shuffle and split 10% validation data\n",
    "x_shuf, y_shuf = sklearn.utils.shuffle(x, y, random_state=0)\n",
    "split = round(x_shuf.shape[0]*0.9)\n",
    "x_val, y_val = (x_shuf[split:, :], y_shuf[split:, :])\n",
    "x_train, y_train = (x[:split, :], y[:split, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adam Optimizer\n",
    "\n",
    "learn_rate = {0.0001, 0.001, 0.01}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "results_list = []\n",
    "count = 0\n",
    "for learn_rate in [0.0001, 0.001, 0.01]:\n",
    "    for run_num in range(2): \n",
    "        print('{}) learn_rate = {}, run_num = {}'\n",
    "              .format(count, learn_rate, run_num))\n",
    "        count += 1\n",
    "        graph_params = {'batch_size': 32,\n",
    "                        'vocab_size': np.max(x)+1,\n",
    "                        'embed_size': 128,\n",
    "                        'hid_size': 128,\n",
    "                        'neg_samples': 64,\n",
    "                        'learn_rate': learn_rate,\n",
    "                        'embed_noise': 1,\n",
    "                        'hid_noise': 0.3,\n",
    "                        'optimizer': 'Adam'}  # name for model save\n",
    "        model = WindowModel(graph_params)\n",
    "        results = model.train(x_train, y_train, x_val, y_val, epochs=20, verbose=False)\n",
    "        results_list.append((graph_params, results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_results(results_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
